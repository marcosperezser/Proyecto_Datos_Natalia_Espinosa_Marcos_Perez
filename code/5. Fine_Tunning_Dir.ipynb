{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8UEcu6QOENwC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\casa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Q0EwQw1DzP3"
      },
      "outputs": [],
      "source": [
        "path_to_json = 'full_format_recipes.json'\n",
        "data = pd.read_json(path_to_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N3FcjBrgEPQo"
      },
      "outputs": [],
      "source": [
        "data.replace(r'^\\s*$', np.nan, regex=True, inplace=True)  # Reemplazar cadenas vacías por NaN\n",
        "data_clean = data.dropna()\n",
        "\n",
        "descripciones = data_clean['desc'].tolist()\n",
        "direcciones = data_clean['directions'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9sPK7n4TEX9w",
        "outputId": "5584ad77-9ba9-4e78-c112-fa2b0e0c8313"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "  1%|          | 10/1061 [00:16<28:37,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 13.6635, 'grad_norm': 132.43153381347656, 'learning_rate': 5e-05, 'epoch': 0.01}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 20/1061 [00:33<28:38,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 5.04, 'grad_norm': 36.22388458251953, 'learning_rate': 4.952426260704092e-05, 'epoch': 0.02}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 30/1061 [00:49<28:21,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4383, 'grad_norm': 10.067452430725098, 'learning_rate': 4.904852521408183e-05, 'epoch': 0.03}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 40/1061 [01:06<28:24,  1.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.1546, 'grad_norm': 4.803162574768066, 'learning_rate': 4.8572787821122746e-05, 'epoch': 0.04}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 50/1061 [01:23<28:18,  1.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8377, 'grad_norm': 21.665586471557617, 'learning_rate': 4.8097050428163656e-05, 'epoch': 0.05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 60/1061 [01:39<27:37,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.2096, 'grad_norm': 9.642337799072266, 'learning_rate': 4.7621313035204566e-05, 'epoch': 0.06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 70/1061 [01:56<27:22,  1.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5278, 'grad_norm': 4.690475940704346, 'learning_rate': 4.714557564224548e-05, 'epoch': 0.07}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 80/1061 [02:12<26:51,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1836, 'grad_norm': 10.131820678710938, 'learning_rate': 4.666983824928639e-05, 'epoch': 0.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 90/1061 [02:29<26:23,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8263, 'grad_norm': 18.705177307128906, 'learning_rate': 4.619410085632731e-05, 'epoch': 0.08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 100/1061 [02:45<26:15,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6328, 'grad_norm': 5.273403167724609, 'learning_rate': 4.5718363463368227e-05, 'epoch': 0.09}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 110/1061 [03:02<25:54,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1727, 'grad_norm': 9.609236717224121, 'learning_rate': 4.524262607040914e-05, 'epoch': 0.1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█▏        | 120/1061 [03:18<25:31,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.0338, 'grad_norm': 22.64391326904297, 'learning_rate': 4.476688867745005e-05, 'epoch': 0.11}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 130/1061 [03:34<25:15,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8218, 'grad_norm': 22.91121482849121, 'learning_rate': 4.4291151284490963e-05, 'epoch': 0.12}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 140/1061 [03:50<25:05,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5179, 'grad_norm': 2.5691187381744385, 'learning_rate': 4.3815413891531873e-05, 'epoch': 0.13}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 150/1061 [04:07<24:55,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6752, 'grad_norm': 29.19272232055664, 'learning_rate': 4.333967649857279e-05, 'epoch': 0.14}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 160/1061 [04:23<24:44,  1.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.414, 'grad_norm': 14.106046676635742, 'learning_rate': 4.286393910561371e-05, 'epoch': 0.15}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 170/1061 [04:40<24:21,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4363, 'grad_norm': 3.2831244468688965, 'learning_rate': 4.238820171265462e-05, 'epoch': 0.16}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 180/1061 [04:56<23:58,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.602, 'grad_norm': 3.275811195373535, 'learning_rate': 4.1912464319695534e-05, 'epoch': 0.17}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 190/1061 [05:12<23:32,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.9689, 'grad_norm': 18.545124053955078, 'learning_rate': 4.1436726926736444e-05, 'epoch': 0.18}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 200/1061 [05:29<23:10,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0013, 'grad_norm': 12.05911922454834, 'learning_rate': 4.0960989533777354e-05, 'epoch': 0.19}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 210/1061 [05:45<23:09,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.4142, 'grad_norm': 28.815481185913086, 'learning_rate': 4.048525214081827e-05, 'epoch': 0.2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 220/1061 [06:01<22:43,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6045, 'grad_norm': 11.386752128601074, 'learning_rate': 4.000951474785918e-05, 'epoch': 0.21}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 230/1061 [06:18<22:26,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.7467, 'grad_norm': 14.776989936828613, 'learning_rate': 3.95337773549001e-05, 'epoch': 0.22}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 240/1061 [06:34<22:21,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6537, 'grad_norm': 28.03081703186035, 'learning_rate': 3.9058039961941014e-05, 'epoch': 0.23}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▎       | 250/1061 [06:50<21:55,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6401, 'grad_norm': 8.471131324768066, 'learning_rate': 3.8582302568981925e-05, 'epoch': 0.24}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 260/1061 [07:07<21:51,  1.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.0362, 'grad_norm': 9.26048469543457, 'learning_rate': 3.8106565176022835e-05, 'epoch': 0.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 270/1061 [07:23<21:23,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3115, 'grad_norm': 6.096595287322998, 'learning_rate': 3.763082778306375e-05, 'epoch': 0.25}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 280/1061 [07:39<21:07,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.3086, 'grad_norm': 34.36260223388672, 'learning_rate': 3.715509039010466e-05, 'epoch': 0.26}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 290/1061 [07:55<20:51,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9555, 'grad_norm': 7.435389041900635, 'learning_rate': 3.667935299714558e-05, 'epoch': 0.27}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 300/1061 [08:12<20:36,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.484, 'grad_norm': 17.066041946411133, 'learning_rate': 3.620361560418649e-05, 'epoch': 0.28}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 310/1061 [08:29<21:43,  1.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4282, 'grad_norm': 15.281428337097168, 'learning_rate': 3.5727878211227405e-05, 'epoch': 0.29}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 320/1061 [08:45<20:04,  1.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3644, 'grad_norm': 25.662216186523438, 'learning_rate': 3.525214081826832e-05, 'epoch': 0.3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 330/1061 [09:01<19:42,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2113, 'grad_norm': 16.846323013305664, 'learning_rate': 3.477640342530923e-05, 'epoch': 0.31}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 340/1061 [09:17<19:30,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8277, 'grad_norm': 10.636877059936523, 'learning_rate': 3.430066603235014e-05, 'epoch': 0.32}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 350/1061 [09:34<19:09,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1319, 'grad_norm': 27.511198043823242, 'learning_rate': 3.382492863939106e-05, 'epoch': 0.33}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 360/1061 [09:50<18:50,  1.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.9575, 'grad_norm': 24.745065689086914, 'learning_rate': 3.334919124643197e-05, 'epoch': 0.34}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 370/1061 [10:06<18:37,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9843, 'grad_norm': 4.587541580200195, 'learning_rate': 3.2873453853472886e-05, 'epoch': 0.35}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 380/1061 [10:22<18:25,  1.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.41, 'grad_norm': 21.282426834106445, 'learning_rate': 3.23977164605138e-05, 'epoch': 0.36}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 390/1061 [10:35<14:25,  1.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.663, 'grad_norm': 12.733410835266113, 'learning_rate': 3.192197906755471e-05, 'epoch': 0.37}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 400/1061 [10:48<14:01,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.4118, 'grad_norm': 18.67781639099121, 'learning_rate': 3.144624167459562e-05, 'epoch': 0.38}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▊      | 410/1061 [11:01<13:49,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.9258, 'grad_norm': 5.867391586303711, 'learning_rate': 3.097050428163654e-05, 'epoch': 0.39}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 420/1061 [11:14<14:08,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6656, 'grad_norm': 24.951547622680664, 'learning_rate': 3.049476688867745e-05, 'epoch': 0.4}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 430/1061 [11:27<14:06,  1.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.9796, 'grad_norm': 33.739891052246094, 'learning_rate': 3.0019029495718366e-05, 'epoch': 0.41}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 440/1061 [11:41<13:11,  1.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.9097, 'grad_norm': 21.048171997070312, 'learning_rate': 2.954329210275928e-05, 'epoch': 0.41}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 450/1061 [11:53<12:28,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1541, 'grad_norm': 24.830135345458984, 'learning_rate': 2.9067554709800193e-05, 'epoch': 0.42}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 460/1061 [12:05<12:20,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5806, 'grad_norm': 68.99971008300781, 'learning_rate': 2.8591817316841106e-05, 'epoch': 0.43}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 470/1061 [12:17<12:05,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1451, 'grad_norm': 21.589874267578125, 'learning_rate': 2.8116079923882016e-05, 'epoch': 0.44}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 480/1061 [12:30<11:55,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.9487, 'grad_norm': 8.669411659240723, 'learning_rate': 2.764034253092293e-05, 'epoch': 0.45}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 490/1061 [12:42<11:41,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4128, 'grad_norm': 10.61294174194336, 'learning_rate': 2.7164605137963843e-05, 'epoch': 0.46}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 500/1061 [12:54<11:27,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5221, 'grad_norm': 13.719630241394043, 'learning_rate': 2.668886774500476e-05, 'epoch': 0.47}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 510/1061 [13:08<11:26,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7721, 'grad_norm': 25.15228843688965, 'learning_rate': 2.6213130352045673e-05, 'epoch': 0.48}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 520/1061 [13:20<11:06,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1148, 'grad_norm': 25.630935668945312, 'learning_rate': 2.5737392959086587e-05, 'epoch': 0.49}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 530/1061 [13:32<10:50,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2754, 'grad_norm': 29.371397018432617, 'learning_rate': 2.52616555661275e-05, 'epoch': 0.5}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 540/1061 [13:45<10:43,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.7177, 'grad_norm': 11.8334321975708, 'learning_rate': 2.4785918173168414e-05, 'epoch': 0.51}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 550/1061 [13:57<10:27,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.679, 'grad_norm': 9.533391952514648, 'learning_rate': 2.4310180780209327e-05, 'epoch': 0.52}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 560/1061 [14:09<10:14,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9409, 'grad_norm': 23.22347640991211, 'learning_rate': 2.3834443387250237e-05, 'epoch': 0.53}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 570/1061 [14:22<10:04,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0628, 'grad_norm': 1.6757489442825317, 'learning_rate': 2.3358705994291154e-05, 'epoch': 0.54}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 580/1061 [14:34<09:48,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8491, 'grad_norm': 8.43675422668457, 'learning_rate': 2.2882968601332067e-05, 'epoch': 0.55}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 590/1061 [14:46<09:37,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.0278, 'grad_norm': 33.28837585449219, 'learning_rate': 2.2407231208372977e-05, 'epoch': 0.56}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 600/1061 [14:59<09:24,  1.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.032, 'grad_norm': 34.37202835083008, 'learning_rate': 2.193149381541389e-05, 'epoch': 0.57}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 610/1061 [15:11<09:15,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.1238, 'grad_norm': 8.662797927856445, 'learning_rate': 2.1455756422454808e-05, 'epoch': 0.57}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 620/1061 [15:23<09:03,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3815, 'grad_norm': 17.08553123474121, 'learning_rate': 2.098001902949572e-05, 'epoch': 0.58}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 630/1061 [15:36<08:56,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.7924, 'grad_norm': 31.020246505737305, 'learning_rate': 2.050428163653663e-05, 'epoch': 0.59}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 640/1061 [15:48<08:40,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.4033, 'grad_norm': 31.072303771972656, 'learning_rate': 2.0028544243577545e-05, 'epoch': 0.6}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 650/1061 [16:01<09:19,  1.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4374, 'grad_norm': 28.822362899780273, 'learning_rate': 1.955280685061846e-05, 'epoch': 0.61}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 660/1061 [16:13<07:32,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.1246, 'grad_norm': 21.106542587280273, 'learning_rate': 1.907706945765937e-05, 'epoch': 0.62}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 670/1061 [16:24<07:17,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3572, 'grad_norm': 8.12912654876709, 'learning_rate': 1.8601332064700285e-05, 'epoch': 0.63}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 680/1061 [16:36<07:30,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.6281, 'grad_norm': 29.339580535888672, 'learning_rate': 1.81255946717412e-05, 'epoch': 0.64}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 690/1061 [16:47<06:26,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.238, 'grad_norm': 10.136873245239258, 'learning_rate': 1.7649857278782115e-05, 'epoch': 0.65}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 700/1061 [16:57<06:31,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2985, 'grad_norm': 13.888323783874512, 'learning_rate': 1.7174119885823025e-05, 'epoch': 0.66}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 710/1061 [17:07<05:47,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.287, 'grad_norm': 34.208213806152344, 'learning_rate': 1.669838249286394e-05, 'epoch': 0.67}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 720/1061 [17:18<05:57,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6592, 'grad_norm': 33.23435974121094, 'learning_rate': 1.6222645099904855e-05, 'epoch': 0.68}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 730/1061 [17:28<05:41,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5527, 'grad_norm': 19.97476577758789, 'learning_rate': 1.5746907706945765e-05, 'epoch': 0.69}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 740/1061 [17:39<05:56,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3424, 'grad_norm': 7.361581325531006, 'learning_rate': 1.527117031398668e-05, 'epoch': 0.7}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 750/1061 [17:52<06:52,  1.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5938, 'grad_norm': 22.877412796020508, 'learning_rate': 1.4795432921027594e-05, 'epoch': 0.71}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 760/1061 [18:03<05:20,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2572, 'grad_norm': 16.156583786010742, 'learning_rate': 1.4319695528068507e-05, 'epoch': 0.72}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 770/1061 [18:14<05:15,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9261, 'grad_norm': 3.5303611755371094, 'learning_rate': 1.3843958135109419e-05, 'epoch': 0.73}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▎  | 780/1061 [18:25<04:48,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.7529, 'grad_norm': 14.281705856323242, 'learning_rate': 1.3368220742150334e-05, 'epoch': 0.74}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 790/1061 [18:35<04:59,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6849, 'grad_norm': 3.44814395904541, 'learning_rate': 1.2892483349191248e-05, 'epoch': 0.74}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 800/1061 [18:47<04:52,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5788, 'grad_norm': 13.211359977722168, 'learning_rate': 1.2416745956232161e-05, 'epoch': 0.75}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 810/1061 [18:57<04:23,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8446, 'grad_norm': 11.011384010314941, 'learning_rate': 1.1941008563273073e-05, 'epoch': 0.76}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 820/1061 [19:08<04:26,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2704, 'grad_norm': 11.410271644592285, 'learning_rate': 1.1465271170313988e-05, 'epoch': 0.77}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 830/1061 [19:21<05:05,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5516, 'grad_norm': 30.113908767700195, 'learning_rate': 1.09895337773549e-05, 'epoch': 0.78}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 840/1061 [19:32<03:56,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3209, 'grad_norm': 29.09003257751465, 'learning_rate': 1.0513796384395815e-05, 'epoch': 0.79}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 850/1061 [19:44<03:50,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.8404, 'grad_norm': 22.458105087280273, 'learning_rate': 1.0038058991436728e-05, 'epoch': 0.8}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 860/1061 [19:56<04:24,  1.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3393, 'grad_norm': 19.404251098632812, 'learning_rate': 9.56232159847764e-06, 'epoch': 0.81}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 870/1061 [20:09<03:40,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5686, 'grad_norm': 31.99281883239746, 'learning_rate': 9.086584205518555e-06, 'epoch': 0.82}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 880/1061 [20:20<03:22,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.7247, 'grad_norm': 4.311183929443359, 'learning_rate': 8.610846812559467e-06, 'epoch': 0.83}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 890/1061 [20:31<03:18,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.2101, 'grad_norm': 16.816936492919922, 'learning_rate': 8.135109419600382e-06, 'epoch': 0.84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▍ | 900/1061 [20:43<03:05,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.199, 'grad_norm': 45.016685485839844, 'learning_rate': 7.659372026641294e-06, 'epoch': 0.85}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 910/1061 [20:54<02:50,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4994, 'grad_norm': 9.338199615478516, 'learning_rate': 7.183634633682209e-06, 'epoch': 0.86}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 920/1061 [21:06<02:41,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5483, 'grad_norm': 14.815545082092285, 'learning_rate': 6.707897240723121e-06, 'epoch': 0.87}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 930/1061 [21:17<02:33,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.6225, 'grad_norm': 19.71107292175293, 'learning_rate': 6.232159847764035e-06, 'epoch': 0.88}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▊ | 940/1061 [21:29<02:22,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.692, 'grad_norm': 4.710208415985107, 'learning_rate': 5.756422454804948e-06, 'epoch': 0.89}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 950/1061 [21:40<02:04,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.5251, 'grad_norm': 11.773701667785645, 'learning_rate': 5.2806850618458615e-06, 'epoch': 0.9}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 960/1061 [21:52<02:03,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.1056, 'grad_norm': 9.140661239624023, 'learning_rate': 4.804947668886775e-06, 'epoch': 0.9}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 970/1061 [22:04<01:51,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.6742, 'grad_norm': 5.537801265716553, 'learning_rate': 4.3292102759276875e-06, 'epoch': 0.91}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 980/1061 [22:17<01:39,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.3457, 'grad_norm': 8.456594467163086, 'learning_rate': 3.853472882968601e-06, 'epoch': 0.92}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 990/1061 [22:29<01:22,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.7929, 'grad_norm': 34.4231071472168, 'learning_rate': 3.377735490009515e-06, 'epoch': 0.93}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 1000/1061 [22:40<01:13,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8664, 'grad_norm': 3.3932361602783203, 'learning_rate': 2.901998097050428e-06, 'epoch': 0.94}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 1010/1061 [22:53<01:02,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8372, 'grad_norm': 8.625835418701172, 'learning_rate': 2.4262607040913416e-06, 'epoch': 0.95}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 1020/1061 [23:05<00:47,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8462, 'grad_norm': 14.878179550170898, 'learning_rate': 1.950523311132255e-06, 'epoch': 0.96}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 1030/1061 [23:17<00:35,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.8411, 'grad_norm': 17.88118553161621, 'learning_rate': 1.4747859181731685e-06, 'epoch': 0.97}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 1040/1061 [23:28<00:24,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.9965, 'grad_norm': 19.92991065979004, 'learning_rate': 9.99048525214082e-07, 'epoch': 0.98}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 1050/1061 [23:40<00:12,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.1699, 'grad_norm': 12.564977645874023, 'learning_rate': 5.233111322549952e-07, 'epoch': 0.99}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 1060/1061 [23:51<00:01,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.4611, 'grad_norm': 30.085477828979492, 'learning_rate': 4.757373929590866e-08, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1061/1061 [23:53<00:00,  1.35s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 1433.3727, 'train_samples_per_second': 5.92, 'train_steps_per_second': 0.74, 'train_loss': 1.7795007240086878, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 67/67 [01:03<00:00,  1.05it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./fine-tuned-bert\\\\tokenizer_config.json',\n",
              " './fine-tuned-bert\\\\special_tokens_map.json',\n",
              " './fine-tuned-bert\\\\vocab.txt',\n",
              " './fine-tuned-bert\\\\added_tokens.json')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "# 1. Cargamos los datos\n",
        "\n",
        "texts = data_clean['desc']  # Usar 'desc' como entrada, reemplazar NaN por cadenas vacías\n",
        "labels = data_clean['rating']  # Usar 'rating' como salida\n",
        "\n",
        "# 2. Dividimos los datos en entrenamiento y prueba\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Tokenizamos los datos\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
        "\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=64)\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=64)\n",
        "\n",
        "# 4. Creamos el Dataset compatible con PyTorch\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels.iloc[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Dataset(train_encodings, train_labels)\n",
        "test_dataset = Dataset(test_encodings, test_labels)\n",
        "\n",
        "# 5. Cargamos el modelo preentrenado para regresión\n",
        "\n",
        "# 6. Configuraramos el entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Directorio de salida\n",
        "    num_train_epochs=1,              # Número de épocas\n",
        "    per_device_train_batch_size=8,  # Tamaño del batch\n",
        "    per_device_eval_batch_size=32,   # Tamaño del batch para evaluación\n",
        "    warmup_steps = 10,\n",
        "    weight_decay = 0.01,\n",
        "    logging_dir = './logs',\n",
        "    logging_steps=10,\n",
        "\n",
        ")\n",
        "\n",
        "# 7. Entrenamos el modelo\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# 8. Evaluaramos y guardamos el modelo\n",
        "trainer.evaluate()\n",
        "model.save_pretrained('./fine-tuned-bert')\n",
        "tokenizer.save_pretrained('./fine-tuned-bert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WAu7dGDaEIOW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('./fine-tuned-bert');\n",
        "model = BertModel.from_pretrained('./fine-tuned-bert', output_hidden_states=True)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zdsv0z__E9Fp"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_embed(text_list):\n",
        "\n",
        "    embeddings = []\n",
        "    for idx, text in enumerate(text_list):\n",
        "\n",
        "        if isinstance(text, list):\n",
        "            text = \" \".join(text)\n",
        "\n",
        "        # Prepararamos el texto con los tokens especiales de BERT\n",
        "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "        # Tokenizamos el texto\n",
        "        tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "        if len(tokenized_text) > 512:\n",
        "            tokenized_text = tokenized_text[:511] + [\"[SEP]\"]\n",
        "\n",
        "        # Mapeamos los tokens a sus índices en el vocabulario\n",
        "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "        # Creamos el segmento alternando entre 0 y 1 por frase\n",
        "        segment_id = idx % 2  # Alterna entre 0 y 1\n",
        "        segments_ids = [segment_id] * len(tokenized_text)\n",
        "\n",
        "        # Creamos tensores para los tokens y los segmentos\n",
        "        tokens_tensor = torch.tensor([indexed_tokens])\n",
        "        segments_tensor = torch.tensor([segments_ids])\n",
        "\n",
        "        # Generaramos embeddings con BERT\n",
        "        with torch.no_grad():\n",
        "            outputs = model(tokens_tensor, segments_tensor)\n",
        "            hidden_states = outputs.last_hidden_state\n",
        "\n",
        "        # Promediamos las representaciones de todos los tokens para obtener el embedding del texto\n",
        "        text_embedding = torch.mean(hidden_states, dim=1).squeeze().tolist()\n",
        "        embeddings.append(text_embedding)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C9p3EgRiF9nr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\casa\\AppData\\Local\\Temp\\ipykernel_3612\\1448779465.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_clean['desc_embeddings'] = desc_embeddings\n"
          ]
        }
      ],
      "source": [
        "desc_embeddings = tokenize_and_embed(descripciones)\n",
        "data_clean['desc_embeddings'] = desc_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "juehp6hTFH-m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10608, 4)\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import hstack\n",
        "from gensim.matutils import corpus2csc\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Seleccionamos las K mejores características del TF-IDF\n",
        "selector = SelectKBest(f_regression, k=100)  # Selecciona 100 características más relevantes\n",
        "\n",
        "x_data = data_clean['desc_embeddings'].tolist()\n",
        "\n",
        "# Reducimos dimensionalidad con PCA\n",
        "pca = PCA(n_components=100)  # Reducir a 100 componentes principales\n",
        "data_reduced = csr_matrix(pca.fit_transform(x_data))\n",
        "\n",
        "numerical_features = data_clean[['calories', 'protein', 'fat', 'sodium']].values\n",
        "\n",
        "print(numerical_features.shape)  \n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "numerical_features_sparse = csr_matrix(numerical_features)\n",
        "# Combinamos TF-IDF reducido con las columnas numéricas\n",
        "\n",
        "x_data_combined = hstack([data_reduced, numerical_features_sparse])\n",
        "\n",
        "\n",
        "# Convertimos las categorías en variables binarias\n",
        "mlb = MultiLabelBinarizer()\n",
        "categories_encoded = pd.DataFrame(\n",
        "    mlb.fit_transform(data_clean['categories']),\n",
        "    columns=mlb.classes_,\n",
        "    index=data_clean.index\n",
        ")\n",
        "\n",
        "# Añadimos las categorías codificadas al DataFrame original\n",
        "categories_sparse = csr_matrix(categories_encoded.values)\n",
        "\n",
        "x_data_combined = hstack([x_data_combined, categories_sparse])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f5czewVuGJ6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 1.4051807917003667\n",
            "MAE: 0.796064842972369\n",
            "R2: 0.11734697898491231\n"
          ]
        }
      ],
      "source": [
        "#RANDOM-FOREST FINE-TUNNING\n",
        "from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, r2_score as r2\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Obtenemos x_data (TF-IDF corpus) y y_data\n",
        "y_data = data_clean['rating']\n",
        "\n",
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_data_combined, y_data, test_size=0.20, random_state=42)\n",
        "\n",
        "# Dividimos el conjunto de entrenamiento en train_val y val\n",
        "X_train_val, X_val, Y_train_val, Y_val = train_test_split(X_train, Y_train, test_size=0.30, random_state=42)\n",
        "\n",
        "# Convertimos a matriz densa para usar con StandardScaler\n",
        "X_train_val = X_train_val.toarray()\n",
        "X_val = X_val.toarray()\n",
        "X_test = X_test.toarray()\n",
        "\n",
        "# Escalamos los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Configuramos el modelo Random Forest y la búsqueda en cuadrícula\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, 30, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [ 'sqrt']\n",
        "}\n",
        "\n",
        "#grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Entrenar el modelo con la búsqueda de hiperparámetros\n",
        "#grid_search.fit(X_train_val_scaled, Y_train_val)\n",
        "#best_params = grid_search.best_params_\n",
        "\n",
        "#print(\"Best parameters found:\", best_params)\n",
        "\n",
        "# Entrenamos el modelo con los mejores parámetros\n",
        "model_original = RandomForestRegressor(\n",
        "    n_estimators=500,\n",
        "    max_depth=50,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    max_features='sqrt',\n",
        "    random_state=42)\n",
        "model_original.fit(X_train_val_scaled, Y_train_val)\n",
        "Y_predict = model_original.predict(X_test_scaled)\n",
        "\n",
        "# Evaluamos el modelo\n",
        "MSE_original = mse(Y_test, Y_predict)\n",
        "MAE_original = mae(Y_test, Y_predict)\n",
        "R2_original = r2(Y_test, Y_predict)\n",
        "\n",
        "print(f\"MSE: {MSE_original}\")\n",
        "print(f\"MAE: {MAE_original}\")\n",
        "print(f\"R2: {R2_original}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jtYmTM1RGTF0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 3730.4982\n",
            "Epoch 2, Training Loss: 1859.0912\n",
            "Epoch 3, Training Loss: 497.3343\n",
            "Epoch 4, Training Loss: 359.6677\n",
            "Epoch 5, Training Loss: 330.5455\n",
            "Epoch 6, Training Loss: 314.4824\n",
            "Epoch 7, Training Loss: 300.7600\n",
            "Epoch 8, Training Loss: 288.1559\n",
            "Epoch 9, Training Loss: 278.6870\n",
            "Epoch 10, Training Loss: 270.4228\n",
            "Epoch 11, Training Loss: 260.3098\n",
            "Epoch 12, Training Loss: 252.6835\n",
            "Epoch 13, Training Loss: 244.8431\n",
            "Epoch 14, Training Loss: 235.6489\n",
            "Epoch 15, Training Loss: 228.4026\n",
            "Epoch 16, Training Loss: 220.3535\n",
            "Epoch 17, Training Loss: 212.0309\n",
            "Epoch 18, Training Loss: 204.3385\n",
            "Epoch 19, Training Loss: 196.1488\n",
            "Epoch 20, Training Loss: 188.3479\n",
            "Test loss: 1.4507546424865723\n",
            "R^2 Score: 0.0887\n"
          ]
        }
      ],
      "source": [
        "#RED NEURONAL FINE-TUNNGING\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "random_state = 42\n",
        "# Fijar semillas para reproducibilidad\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(random_state)\n",
        "\n",
        "# Definición del modelo\n",
        "class RegressionNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(RegressionNN, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 25),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(25, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Función principal\n",
        "def NN_eval(X, y):\n",
        "    # Estandarizar los datos\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "\n",
        "    # Convertir a tensores\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    # Crear DataLoader\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # Inicializar modelo, función de pérdida y optimizador\n",
        "    model = RegressionNN(input_dim=X_train.shape[1])\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # Ciclo de entrenamiento\n",
        "    for epoch in range(20):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Training Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Evaluación del modelo\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "        predictions = model(X_test_tensor)\n",
        "        test_loss = criterion(predictions, y_test_tensor)\n",
        "        print(f\"Test loss: {test_loss.item()}\")\n",
        "\n",
        "        # Conversión a NumPy y cálculo de R^2\n",
        "        predictions_np = predictions.cpu().numpy()\n",
        "        r2 = r2_score(y_test, predictions_np)\n",
        "        print(f\"R^2 Score: {r2:.4f}\")\n",
        "\n",
        "NN_eval(x_data_combined.toarray(), data_clean['rating'].tolist())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
